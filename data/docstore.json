{"docstore/metadata": {"https://innovation.ebayinc.com/tech/features/cutting-through-the-noise-three-things-weve-learned-about-generative-ai-and-developer-productivity/": {"doc_hash": "0000d332f8989706162b549d1334ba4c6737e12b6cc1cb0b525d7d04c0f812a0"}, "1ecf3049-731a-45f4-95ac-298ac3b21ae6": {"doc_hash": "3ef6e0e31a5e49c946e0ac8e467c1d425186ea47cd6ea76a20c3e088bed346fe", "ref_doc_id": "https://innovation.ebayinc.com/tech/features/cutting-through-the-noise-three-things-weve-learned-about-generative-ai-and-developer-productivity/"}, "a8dae478-f090-4ca3-9cf6-640267eea2d7": {"doc_hash": "24a69d712b1cd45371b5bdf73b08f96c908bb24a0f3cfe3c2ef35a89e4153d2e", "ref_doc_id": "https://innovation.ebayinc.com/tech/features/cutting-through-the-noise-three-things-weve-learned-about-generative-ai-and-developer-productivity/"}}, "docstore/data": {"1ecf3049-731a-45f4-95ac-298ac3b21ae6": {"__data__": {"id_": "1ecf3049-731a-45f4-95ac-298ac3b21ae6", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "https://innovation.ebayinc.com/tech/features/cutting-through-the-noise-three-things-weve-learned-about-generative-ai-and-developer-productivity/", "node_type": "4", "metadata": {}, "hash": "0000d332f8989706162b549d1334ba4c6737e12b6cc1cb0b525d7d04c0f812a0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a8dae478-f090-4ca3-9cf6-640267eea2d7", "node_type": "1", "metadata": {}, "hash": "24a69d712b1cd45371b5bdf73b08f96c908bb24a0f3cfe3c2ef35a89e4153d2e", "class_name": "RelatedNodeInfo"}}, "text": "The pace of innovation is faster than ever before, and through our AI work at eBay, we believe we\u2019ve unlocked three major tracks to developer productivity: utilizing a commercial offering, fine-tuning an existing Large Language Model (LLM), and leveraging an internal network. Each of these tracks requires additional resources to integrate, but it\u2019s not a matter of ranking them \u201cgood, better, or best.\u201d Each can be used separately or in any combination, and bring their own benefits and drawbacks. Using all three of these options, we created an exercise with results we believe can be of interest and use to the wider developer community.\nAs a note: there is no reliable single metric to measure developer productivity given its complexity. Instead, as suggested by studies, we use both quantitative and qualitative metrics. The former includes tools like Git, DORA and Flow, and measuring code quality and performance. The latter is measured with targeted developer surveys.\nTrack 1: Existing Offerings\nMany companies and products have popped up in recent years to take advantage of advances in AI. These are sometimes standalone commercial products, and sometimes tools built on existing open source LLMs, like Llama or Gemma.\nWe expanded our use of GitHub Copilot, a commercial offering, to all of our developers last year. Our test for this track involved a, well, pilot for Copilot, comprising 300 developers \u2013 half using Copilot, and half forming a control group with similar assignments and abilities but without Copilot, in an A/B test experiment conducted in the summer of 2023. We chose Copilot because of its popularity in the developer world, and because eBay already has our codebase on GitHub; we\u2019re familiar with the way their products work.\nWhat worked? Our results were very positive. Following a two-week ramp-up period, developer surveys showed that the developers using Copilot saw an increase in perceived productivity, along with a 27% code acceptance rate (as reported through Copilot telemetry). We also found good levels of accuracy: the generated documents were 70% accurate, and the generated code was at 60%. Additionally, for the experimental Copilot group, we saw a 17% decrease in pull request (PR) creation to merge time, and a 12% decrease in Lead Time for Change \u2013 an indirect benefit of efficient coding. The code quality measure through Sonar remained the same for both groups.\nCopilot was able to provide features including converting comments to code, suggesting the next line of code, generating tests, and auto-filling repetitive code \u2013 all time-saving measures. But it also had drawbacks.\nWhat didn\u2019t work so well? Copilot has a limit to its prompt size \u2013 essentially, how much data it can process. LLMs are improving the context size with each iteration, and for some uses this won\u2019t be a problem at all. For a company of eBay\u2019s size, though, certain tasks are simply not possible. We\u2019ve got millions of lines of code, and some activities require the knowledge of the entire eBay codebase.\nTrack 2: Post-Trained and Fine-Tuned LLMs\nExisting open source LLMs can sometimes reach an upper limit of productivity; after all, there\u2019s only so much we can learn from a model that doesn\u2019t incorporate our internal data. So, a second track is to post-train and fine-tune open source LLMs using our organization\u2019s own pre-processed data.\nWe used Code Llama 13B as our base LLM for this exercise, though that can be easily swapped for another if the need arises. To see how well a post-trained and fine-tuned existing LLM could work, we created what we call eBayCoder: Code Llama that\u2019s trained on eBay\u2019s codebase and associated documentation.\nWhat worked? We found that eBayCoder was able to make some tasks that were previously labor- and time-intensive much easier. For example, software upkeep is critical in all technology organizations. Like other companies at scale, eBay has its own foundational libraries and frameworks built on top of open source software for servers, message queues, batch jobs, iOS, and Android. These systems should be periodically upgraded to improve developer ergonomics and address security vulnerabilities (e.g. upgrading to the latest Spring or Spring Boot). The effort varies from zero to huge, depending on the current version of the application stack. With the existing migration tools at eBay, we still spend significant engineering resources on software upkeep. This is one area where we believe a fine-tuned LLM can have a very large impact already in the short term.\nWith a codebase as large and varied as eBay\u2019s, we also sometimes run into the problem that an existing commercial LLM offering would only have access to data and code that\u2019s immediately relevant to that question, usually the surrounding files, the current repository, and a few dependent libraries.", "start_char_idx": 0, "end_char_idx": 4841, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a8dae478-f090-4ca3-9cf6-640267eea2d7": {"__data__": {"id_": "a8dae478-f090-4ca3-9cf6-640267eea2d7", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "https://innovation.ebayinc.com/tech/features/cutting-through-the-noise-three-things-weve-learned-about-generative-ai-and-developer-productivity/", "node_type": "4", "metadata": {}, "hash": "0000d332f8989706162b549d1334ba4c6737e12b6cc1cb0b525d7d04c0f812a0", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1ecf3049-731a-45f4-95ac-298ac3b21ae6", "node_type": "1", "metadata": {}, "hash": "3ef6e0e31a5e49c946e0ac8e467c1d425186ea47cd6ea76a20c3e088bed346fe", "class_name": "RelatedNodeInfo"}}, "text": "Like other companies at scale, eBay has its own foundational libraries and frameworks built on top of open source software for servers, message queues, batch jobs, iOS, and Android. These systems should be periodically upgraded to improve developer ergonomics and address security vulnerabilities (e.g. upgrading to the latest Spring or Spring Boot). The effort varies from zero to huge, depending on the current version of the application stack. With the existing migration tools at eBay, we still spend significant engineering resources on software upkeep. This is one area where we believe a fine-tuned LLM can have a very large impact already in the short term.\nWith a codebase as large and varied as eBay\u2019s, we also sometimes run into the problem that an existing commercial LLM offering would only have access to data and code that\u2019s immediately relevant to that question, usually the surrounding files, the current repository, and a few dependent libraries. It may not be aware of a different internal service or a non-dependent library maintained by other groups that offer the same functionality currently being authored. This often leads to large amounts of code duplication. But a fine-tuned LLM can access as much context as we want, potentially reducing the amount of code duplication.\nTrack 3: An Internal Knowledge Base\nA significant amount of productive time for any developer is spent in investigation. Some examples of those questions we encounter here at eBay: \u201cWhich API should I call to add an item to the cart?\u201d \u201cWhere do I find the analytics dashboard for new buyers?\u201d \u201cHow do I create a pipeline to deploy my application to production?\u201d\nAt a large company, there is plenty of documentation, but it isn\u2019t necessarily easy to access. Internal information is distributed across primary sources including enterprise GitHub Markdowns, Google Docs, Jira, Slack, and Wikis. Trying to find the answers to seemingly simple questions can sometimes require multiple meetings, dead ends, and red herrings \u2013 all of which adds up to reduced productivity and increased annoyance.\nSo we created an internal GPT that ingests certain data from relevant primary sources. You know how every team and every company has one employee who\u2019s been there a long time and who you go to when you have a question and you aren\u2019t even sure who to ask? That\u2019s what we made. We want our most knowledgeable and experienced developers to focus on innovation.\nWhat worked? At a high level, we used an Retrieval Augmented Generation (RAG) \u2013 a system that creates an embedding vector for each piece of content, which is then stored in a vector database. We were able to make this an automated, recurring task.\nWhen someone enters a query, the system creates an embedding vector, and then uses a similarity mechanism (such as cosine similarity) to compare the query vector against all the known aforementioned content embedding vectors. This step finds the content and links most similar to the person\u2019s query.\nNow, with the query and context in hand, we call our private instance of commercial and open source LLMs with a question of the form: Answer the question as truthfully as possible using the provided context, and if the answer is not contained within the text below, say \u201cI don\u2019t know.\u201d\nWe\u2019re already seeing usage of our internal GPT rise each day, and have significant feedback from folks indicating that they appreciate its efficiency and relevance. To measure its effectiveness more precisely, we\u2019re tracking how long it takes to complete everyday tasks, and also tracking the number of support and meeting requests. We\u2019re excited to share our findings when our sample size is large enough, but early results are promising.\nWhat didn\u2019t work so well? Like with any automated chat system, sometimes these GPTs can deliver nonsensical answers. This can be frustrating or unhelpful at times, but can be improved with consistent effort. At eBay, we depend on our employees to give feedback through the user interface, which is then incorporated into the system itself. This technique \u2013 Reinforcement Learning from Human Feedback, or RLHF \u2013 can make the GPT better over time.\nConclusion\nThese three tracks form the backbone for generative AI developer productivity, and they keep a clear view of what they are and how they benefit each project. The way we develop software is changing. More importantly, the gains we realize from generative AI have a cumulative effect on daily work. The boost in developer productivity is at the beginning of an exponential curve, which we often underestimate, as the trouble with exponential growth is that the curve feels flat in the beginning.\nAs with any transformative technology, AI buzz can be deafening, and we are committed to cutting through the noise to address developer productivity needs efficiently.", "start_char_idx": 3877, "end_char_idx": 8716, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"https://innovation.ebayinc.com/tech/features/cutting-through-the-noise-three-things-weve-learned-about-generative-ai-and-developer-productivity/": {"node_ids": ["1ecf3049-731a-45f4-95ac-298ac3b21ae6", "a8dae478-f090-4ca3-9cf6-640267eea2d7"], "metadata": {}}}}